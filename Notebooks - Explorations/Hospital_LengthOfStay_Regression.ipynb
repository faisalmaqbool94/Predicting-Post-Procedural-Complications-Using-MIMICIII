{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "93872ca38637cdc1a3144b647b710c30108387b4"
   },
   "source": [
    "* The original data is from MIMIC2 - Multiparameter Intelligent Monitoring in Intensive Care (deidentified DB) available freely from \n",
    "https://mimic.physionet.org/\n",
    "* Each instance in the mldata.csv attached is one admission\n",
    "* Testing a theory I have, that one can predict LOS just by the number of interactions betweeen patient and hospital per day, I've used the following features for the LOS prediction as a REGRESSION problem:\n",
    "* Age, Gender, Ethnicity, Insurance, Admission Type, Admission Source, etc.\n",
    "* Number of Diagnosis on Admission, Procedures on Admission\n",
    "* Daily average number of: Labs, Micro labs, IV meds, Non-IV meds, Imaging Reports, Notes, Orders, Caregivers, Careunits\n",
    "\n",
    "The label is LOS in days\n",
    "\n",
    "I've compared initially 12 REGRESSOR models.  \n",
    "\n",
    "\n",
    "Let me know *your* results on this (overly simplified) dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "be5e7a1a7278c138e277e90b019db4961154c731"
   },
   "outputs": [],
   "source": [
    "# IMPORT MODULES\n",
    "# TURN ON the GPU !\n",
    "\n",
    "import os\n",
    "from operator import itemgetter    \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "get_ipython().magic(u'matplotlib inline')\n",
    "plt.style.use('ggplot')\n",
    "\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import Imputer\n",
    "from pandas.tools.plotting import scatter_matrix\n",
    "from sklearn.preprocessing import RobustScaler, StandardScaler, LabelEncoder, MinMaxScaler, OneHotEncoder, LabelBinarizer\n",
    "from sklearn.metrics import mean_squared_error, accuracy_score, mean_absolute_error\n",
    "from sklearn.cross_validation import KFold, cross_val_score\n",
    "from sklearn.model_selection import cross_val_score, GridSearchCV, RandomizedSearchCV, KFold, cross_val_predict, StratifiedKFold, train_test_split, learning_curve, ShuffleSplit\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso, ElasticNet, SGDRegressor, BayesianRidge\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor, ExtraTreesRegressor, BaggingRegressor\n",
    "from sklearn.svm import SVR, LinearSVR\n",
    "from sklearn.kernel_ridge import KernelRidge\n",
    "from xgboost import XGBRegressor\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "from keras import models, regularizers, layers, optimizers, losses, metrics\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.utils import np_utils\n",
    "\n",
    "print(os.getcwd())\n",
    "print(\"Modules imported \\n\")\n",
    "import os\n",
    "print(os.listdir(\"../input\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "d624986c6d662b3dec980c593981fb913cb00c01"
   },
   "outputs": [],
   "source": [
    "# Load MIMIC2 data \n",
    "\n",
    "data = pd.read_csv('../input/mimic3a.csv')\n",
    "print(\"With id\", data.shape)\n",
    "data_full = data.drop('hadm_id', 1)\n",
    "print(\"No id\",data_full.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "a3d700d5763270c86b368668e9ef7af00372c79c",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print(data_full.shape)\n",
    "data_full.info()\n",
    "data_full.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "1fce3fd763d30cf516d00815bb386cd95cea14ec"
   },
   "outputs": [],
   "source": [
    "data_full.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "798b9834d32ba534e5aca36d5763b9624fe00565"
   },
   "outputs": [],
   "source": [
    "# Label = LOS\n",
    "y = data_full['LOSdays']\n",
    "X = data_full.drop('LOSdays', 1)\n",
    "X = X.drop('ExpiredHospital', 1)\n",
    "X = X.drop('AdmitDiagnosis', 1)\n",
    "X = X.drop('AdmitProcedure', 1)\n",
    "X = X.drop('marital_status', 1)\n",
    "X = X.drop('ethnicity', 1)\n",
    "X = X.drop('religion', 1)\n",
    "X = X.drop('insurance', 1)\n",
    "\n",
    "print(\"y - Labels\", y.shape)\n",
    "print(\"X - No Label No id \", X.shape)\n",
    "print(X.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "c9cae3f366d80dfc90273a2aeacb32129284b47a"
   },
   "outputs": [],
   "source": [
    "data_full.hist(bins=30, figsize=(20,15))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "fd41bd691f8a4d8a488486dc8a0be7c4945f804e"
   },
   "outputs": [],
   "source": [
    "age_histogram = data_full.hist(column='age', bins=20, range=[0, 100])\n",
    "for ax in age_histogram.flatten():\n",
    "    ax.set_xlabel(\"Age\")\n",
    "    ax.set_ylabel(\"Num. of Patients\")\n",
    "    \n",
    "age_LOS = data_full.hist(column='LOSdays', bins=20, range=[0, 100])\n",
    "for ax in age_LOS.flatten():\n",
    "    ax.set_xlabel(\"LOS\")\n",
    "    ax.set_ylabel(\"Num. of Patients\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "dfe87481713cb5fd1ca62ec4ad6178eea875fc85"
   },
   "source": [
    "data_full.groupby('insurance').size().plot.bar()\n",
    "plt.show()\n",
    "data_full.groupby('admit_type').size().plot.bar()\n",
    "plt.show()\n",
    "data_full.groupby('admit_location').size().plot.bar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "36494e7db7035fce66b70d3c585e16f7537b37b4"
   },
   "outputs": [],
   "source": [
    "# Pearson linear correlation\n",
    "\n",
    "corr_matrix = data_full.corr()\n",
    "corr_matrix[\"LOSdays\"].sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "8bae4396cb26c3c9c08932f56b860207a2dae336"
   },
   "source": [
    "# IMPUTE missing values\n",
    "\n",
    "X.fillna(value='unknown', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "c2a17ce91d1523ebda4d7ecf75cc6a2b055f814b"
   },
   "outputs": [],
   "source": [
    "# Check that all X columns have no missing values\n",
    "X.info()\n",
    "X.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "e07dfb69dade5add23c0d1a3f9d85042432de1bc"
   },
   "outputs": [],
   "source": [
    "#data_full.plot(kind=\"scatter\", x=\"sofa_max\", xlim=(0,25), y=\"LOS\", alpha=0.1, ylim=(0,50))\n",
    "data_full.plot(kind=\"scatter\", x=\"age\", xlim=(0,100), y=\"LOSdays\", alpha=0.1, ylim=(0,50))\n",
    "data_full.plot(kind=\"scatter\", x=\"TotalNumInteract\", xlim=(0,300), y=\"LOSdays\", alpha=0.1, ylim=(0,50))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "45c8a4a2737cf1a44f6be54e4d4424530e59b096"
   },
   "outputs": [],
   "source": [
    "# MAP Text to Numerical Data\n",
    "# Use one-hot-encoding to convert categorical features to numerical\n",
    "\n",
    "print(X.shape)\n",
    "categorical_columns = [\n",
    "                       'gender',                     \n",
    "                      'admit_type',\n",
    "                      'admit_location'                      \n",
    "                      ]\n",
    "\n",
    "for col in categorical_columns:\n",
    "    #if the original column is present replace it with a one-hot\n",
    "    if col in X.columns:\n",
    "        one_hot_encoded = pd.get_dummies(X[col])\n",
    "        X = X.drop(col, axis=1)\n",
    "        X = X.join(one_hot_encoded, lsuffix='_left', rsuffix='_right')\n",
    "        \n",
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "c3cbb462e2f4320d62da9595582f113c869761c2"
   },
   "outputs": [],
   "source": [
    "print(X.columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "60be44d230f432f3f087f15a238feb21deb68bbf"
   },
   "outputs": [],
   "source": [
    "\n",
    "print(data_full.shape)\n",
    "print(X.shape)\n",
    "#XnotNorm = np.array(X.copy())\n",
    "XnotNorm = X.copy()\n",
    "print('XnotNorm ', XnotNorm.shape)\n",
    "\n",
    "yFI = data_full.LOSdays\n",
    "ynotNorm = yFI.copy()\n",
    "print('ynotNorm ', ynotNorm.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "63cee0b5231c742bacfb4318b16959e4f6394b1b"
   },
   "outputs": [],
   "source": [
    "# Normalize X\n",
    "\n",
    "x = XnotNorm.values #returns a numpy array\n",
    "scaler = preprocessing.StandardScaler()\n",
    "x_scaled = scaler.fit_transform(x)\n",
    "XNorm = pd.DataFrame(x_scaled, columns=XnotNorm.columns)\n",
    "print(XNorm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "01e4e00399f71a76e538a59de2ba00c7439da66d"
   },
   "outputs": [],
   "source": [
    "# Normalize y\n",
    "\n",
    "y = ynotNorm.values #returns a numpy array\n",
    "y = y.reshape(-1, 1)\n",
    "y_scaled = scaler.fit_transform(y)\n",
    "ynorm=pd.DataFrame(y_scaled)\n",
    "print(ynorm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "8834d289ffc44438b8bc00e94c9c4940ee174368"
   },
   "outputs": [],
   "source": [
    "# FEATURE IMPORTANCE Data NOT normalized using Lasso model - NOT the best one ...\n",
    "\n",
    "trainFinalFI = XnotNorm\n",
    "yFinalFI = ynotNorm\n",
    "\n",
    "lasso=Lasso(alpha=0.001, copy_X=True, fit_intercept=True, max_iter=1000,\n",
    "   normalize=False, positive=False, precompute=False, random_state=None,\n",
    "   selection='cyclic', tol=0.0001, warm_start=False)\n",
    "lasso.fit(trainFinalFI,yFinalFI)\n",
    "\n",
    "FI_lasso = pd.DataFrame({\"Feature Importance\":lasso.coef_}, index=trainFinalFI.columns)\n",
    "\n",
    "# Focus on those with 0 importance\n",
    "#print(FI_lasso.sort_values(\"Feature Importance\",ascending=False).to_string())\n",
    "#print(\"_\"*80)\n",
    "FI_lasso[FI_lasso[\"Feature Importance\"] >0.2].sort_values(\"Feature Importance\").plot(kind=\"barh\",figsize=(15,25))\n",
    "plt.xticks(rotation=90)\n",
    "FI_lasso[FI_lasso[\"Feature Importance\"] <-0.2].sort_values(\"Feature Importance\").plot(kind=\"barh\",figsize=(15,25))\n",
    "plt.xticks(rotation=90)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "f03ccf0923716b07035356abcf3acb4a51d23025"
   },
   "outputs": [],
   "source": [
    "# CROSS VALIDATION\n",
    "\n",
    "def rmse_cv(model,X,y):\n",
    "    rmse = np.sqrt(-cross_val_score(model, X, y, scoring=\"neg_mean_squared_error\", cv=5))\n",
    "    return rmse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "3cb38c448548cc567ea6128addd0f76eafe0a17b"
   },
   "source": [
    "# Lin reg ALL models HYPERPARAMS NOT optimized\n",
    "\n",
    "models = [LinearRegression(),Ridge(),Lasso(),RandomForestRegressor(),GradientBoostingRegressor(),SVR(),LinearSVR(),\n",
    "          ElasticNet(),SGDRegressor(),BayesianRidge(),KernelRidge(),ExtraTreesRegressor()]\n",
    "names = [\"LinearRegression\", \"Ridge\", \"Lasso\", \"RandomForestRegressor\", \"GradientBoostingRegressor\", \"SVR\", \"LinearSVR\", \n",
    "         \"ElasticNet\",\"SGDRegressor\",\"BayesianRidge\",\"KernelRidge\",\"ExtraTreesRegressor\"]\n",
    "         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "7ac97c5a62c86428fd7946c1d6ad4230be770aa0"
   },
   "outputs": [],
   "source": [
    "# Lin reg ALL models HYPERPARAMS NOT optimized\n",
    "\n",
    "models = [RandomForestRegressor(), ExtraTreesRegressor(), GradientBoostingRegressor()]\n",
    "names = [\"RandomForestRegressor\", \"ExtraTreesRegressor\", \"GradientBoostingRegressor\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "19d59e54c3f70009768af0742003cea294591357"
   },
   "outputs": [],
   "source": [
    "# Run the models and compare\n",
    "\n",
    "ModScores = {}\n",
    "\n",
    "for name, model in zip(names, models):\n",
    "    score = rmse_cv(model, XNorm, ynorm)\n",
    "    ModScores[name] = score.mean()\n",
    "    print(\"{}: {:.2f}\".format(name,score.mean()))\n",
    "\n",
    "print(\"_\"*100)\n",
    "for key, value in sorted(ModScores.items(), key = itemgetter(1), reverse = False):\n",
    "    print(key, round(value,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "e0d67a66679ee59af083b102408c69db5646ba33"
   },
   "outputs": [],
   "source": [
    "# Optimize hyper params for one model\n",
    "\n",
    "model = RandomForestRegressor()\n",
    "\n",
    "param_grid = [{},]\n",
    "\n",
    "grid_search = GridSearchCV(model, param_grid, cv=5, scoring='neg_mean_squared_error')\n",
    "grid_search.fit(XNorm, ynorm)\n",
    "\n",
    "print(grid_search.best_estimator_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "5a406c3bcd3c161727af4b5dcab74dca35daf853"
   },
   "outputs": [],
   "source": [
    "model = RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=None,\n",
    "           max_features='auto', max_leaf_nodes=None,\n",
    "           min_impurity_decrease=0.0, min_impurity_split=None,\n",
    "           min_samples_leaf=1, min_samples_split=2,\n",
    "           min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,\n",
    "           oob_score=False, random_state=None, verbose=0, warm_start=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "b9097a12c41f10f3b86e0915577ce0d781e4758c"
   },
   "outputs": [],
   "source": [
    "# FEATURE IMPORTANCE - NORMALIZED - last model\n",
    "\n",
    "trainFinalFI = XNorm\n",
    "yFinalFI = ynorm\n",
    "\n",
    "model.fit(trainFinalFI,yFinalFI)\n",
    "\n",
    "FI_model = pd.DataFrame({\"Feature Importance\":model.feature_importances_,}, index=trainFinalFI.columns)\n",
    "FI_model[FI_model[\"Feature Importance\"] > 0.007].sort_values(\"Feature Importance\").plot(kind=\"barh\",figsize=(15,25))\n",
    "plt.xticks(rotation=90)\n",
    "plt.xticks(rotation=90)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "49522e46d392dfcf95d60a54481d1dce22cdef30"
   },
   "outputs": [],
   "source": [
    "# List of important features for model\n",
    "FI_model = pd.DataFrame({\"Feature Importance\":model.feature_importances_,}, index=trainFinalFI.columns)\n",
    "FI_model=FI_model.sort_values('Feature Importance', ascending = False)\n",
    "print(FI_model[FI_model[\"Feature Importance\"] > 0.001])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "9e4dc0ce72a8131e32acda585f4b76061034f7f0"
   },
   "outputs": [],
   "source": [
    "def plot_learning_curve(estimator, title, X, y, ylim=None, cv=None,\n",
    "                        n_jobs=1, train_sizes=np.linspace(.1, 1.0, 5)):\n",
    "    plt.figure()\n",
    "    plt.title(title)\n",
    "    if ylim is not None:\n",
    "        plt.ylim(*ylim)\n",
    "    plt.xlabel(\"Training examples\")\n",
    "    plt.ylabel(\"Error\")\n",
    "    train_sizes, train_scores, test_scores = learning_curve(\n",
    "        estimator, X, y, cv=cv, n_jobs=n_jobs, train_sizes=train_sizes)\n",
    "    train_scores_mean = 1-np.mean(train_scores, axis=1)\n",
    "    train_scores_std = np.std(train_scores, axis=1)\n",
    "    test_scores_mean = 1-np.mean(test_scores, axis=1)\n",
    "    test_scores_std = np.std(test_scores, axis=1)\n",
    "    plt.grid()\n",
    "\n",
    "    plt.fill_between(train_sizes, train_scores_mean - train_scores_std,\n",
    "                     train_scores_mean + train_scores_std, alpha=0.1,\n",
    "                     color=\"r\")\n",
    "    plt.fill_between(train_sizes, test_scores_mean - test_scores_std,\n",
    "                     test_scores_mean + test_scores_std, alpha=0.1, color=\"g\")\n",
    "    plt.plot(train_sizes, train_scores_mean, 'o-', color=\"r\",\n",
    "             label=\"Training score\")\n",
    "    plt.plot(train_sizes, test_scores_mean, 'o-', color=\"g\",\n",
    "             label=\"Cross-validation score\")\n",
    "\n",
    "    plt.legend(loc=\"best\")\n",
    "    return plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "afe92f8617e5290fc0317d2331947583282bac65"
   },
   "outputs": [],
   "source": [
    "# LEARNING CURVES Train / Validation\n",
    "\n",
    "title = \"Learning Curves \"\n",
    "cv = ShuffleSplit(n_splits=10, test_size=0.2, random_state=42)\n",
    "plot_learning_curve(model, title, XNorm, ynorm, cv=cv, n_jobs=5)\n",
    "#plot_learning_curve(model, title, XNorm, y, ylim=(0.01, 0.99), cv=cv, n_jobs=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "528cd53ec44c5592c7d237a56a84d838a0fff0b8"
   },
   "outputs": [],
   "source": [
    "# Split into Train & Test\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(XNorm, ynorm, test_size=0.2, random_state=42)\n",
    "print ('X_train: ', X_train.shape)\n",
    "print ('X_test: ', X_test.shape)\n",
    "print ('y_train: ', y_train.shape)\n",
    "print ('y_test: ', y_test.shape)\n",
    "\n",
    "# Model FINAL fit and evaluation on test\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "final_predictions = model.predict(X_test)\n",
    "final_mse = mean_squared_error(y_test, final_predictions)\n",
    "final_rmse = np.sqrt(final_mse) \n",
    "print(\"NORM rmse on test \", round(final_rmse, 4))\n",
    "\n",
    "final_mae = mean_absolute_error(y_test, final_predictions)\n",
    "print(\"NORM mae on test \", round(final_mae, 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "91574fedd82e85ae7d616e23f4c5174213926f24"
   },
   "outputs": [],
   "source": [
    "# Split into Train & Test\n",
    "\n",
    "#   NOTE - For ed purposes - MAE - ynotNorm was USED !!!\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(XNorm, ynotNorm, test_size=0.2, random_state=42)\n",
    "print ('X_train: ', X_train.shape)\n",
    "print ('X_test: ', X_test.shape)\n",
    "print ('y_train: ', y_train.shape)\n",
    "print ('y_test: ', y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "8861318aed03d33784b219b5a56569e29e396ae2"
   },
   "outputs": [],
   "source": [
    "# Model FINAL fit and evaluation on test\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "final_predictions = model.predict(X_test)\n",
    "final_mse = mean_squared_error(y_test, final_predictions)\n",
    "final_rmse = np.sqrt(final_mse) \n",
    "print(\"rmse on test \", round(final_rmse, 4))\n",
    "\n",
    "final_mae = mean_absolute_error(y_test, final_predictions)\n",
    "print(\"mae on test \", round(final_mae, 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "e3c18714aca39c174cd2c2d747f3ee23c2491362"
   },
   "outputs": [],
   "source": [
    "# PLOT True vs Predicted\n",
    "\n",
    "xChart = [np.array(y_test)]\n",
    "yChart = [np.array(final_predictions)]\n",
    "\n",
    "plt.scatter(xChart,yChart, alpha=0.2)\n",
    "plt.xlim(0,30)\n",
    "plt.ylim(0,30)\n",
    "plt.plot( [0,30],[0,30], 'b')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "27853b996b38fbcf56419a7c9963410928055e53"
   },
   "source": [
    "**NN model**  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "76ce78f1fa0c159fd80c97344a53904606d19f6d"
   },
   "outputs": [],
   "source": [
    "# Split into Train & Test\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(XNorm, ynorm, test_size=0.2, random_state=42)\n",
    "print ('X_train: ', X_train.shape)\n",
    "print ('X_test: ', X_test.shape)\n",
    "print ('y_train: ', y_train.shape)\n",
    "print ('y_test: ', y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "9b45ff6a343f8e9b8a2400dadc703d7cd62a2add"
   },
   "outputs": [],
   "source": [
    "# Transfer data to NN format\n",
    "\n",
    "x_val = X_test\n",
    "partial_x_train = X_train\n",
    "y_val = y_test\n",
    "partial_y_train = y_train\n",
    "\n",
    "print(\"partial_x_train \", partial_x_train.shape)\n",
    "print(\"partial_y_train \", partial_y_train.shape)\n",
    "\n",
    "print(\"x_val \", x_val.shape)\n",
    "print(\"y_val \", y_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "e7261dc54a52f40501e423350f2277c09878553c"
   },
   "outputs": [],
   "source": [
    "# NN MODEL\n",
    "from keras import models\n",
    "model = models.Sequential()\n",
    "model.add(layers.Dense(2048, activation='relu', kernel_regularizer=regularizers.l2(0.001),\n",
    "                       input_shape=(partial_x_train.shape[1],)))\n",
    "#model.add(layers.BatchNormalization())\n",
    "model.add(layers.Dropout(0.5))\n",
    "model.add(layers.Dense(2048, activation='relu', kernel_regularizer=regularizers.l2(0.001)))\n",
    "model.add(layers.Dropout(0.5))\n",
    "model.add(layers.Dense(2048, activation='relu', kernel_regularizer=regularizers.l2(0.001)))\n",
    "model.add(layers.Dropout(0.5))\n",
    "model.add(layers.Dense(2048, activation='relu', kernel_regularizer=regularizers.l2(0.001)))\n",
    "model.add(layers.Dropout(0.5))\n",
    "model.add(layers.Dense(1))\n",
    "model.summary()\n",
    "\n",
    "model.compile(optimizer=optimizers.Adam(lr=1e-4), loss='mse', metrics=['mae'])\n",
    "print(\"model compiled\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "2b319286ed46ccd3263ec2da0e5a110313a76d49",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "history = model.fit(partial_x_train, partial_y_train,\n",
    "                    validation_data=(x_val, y_val), \n",
    "                    verbose=1,\n",
    "                   epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "1c50e9f8b3702332944a2bf4157152474824538d"
   },
   "outputs": [],
   "source": [
    "acc = history.history['mean_absolute_error']\n",
    "val_acc = history.history['val_mean_absolute_error']\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "epochs = range(1, len(acc) + 1)\n",
    "plt.plot(epochs, acc, 'bo', label='Training error')\n",
    "plt.plot(epochs, val_acc, 'r', label='Validation error')\n",
    "plt.title('Training and validation ERROR')\n",
    "plt.legend()\n",
    "plt.figure()\n",
    "plt.plot(epochs, loss, 'bo', label='Training loss')\n",
    "plt.plot(epochs, val_loss, 'r', label='Validation loss')\n",
    "plt.title('Training and validation LOSS')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "f48a107cc154defea00c0b98604350cc587d89a3",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Model evaluation on test\n",
    "\n",
    "test_mse_score, test_mae_score = model.evaluate(x_val, y_val)\n",
    "final_rmse = np.sqrt(test_mse_score) \n",
    "print(\"rmse on test \", round(final_rmse, 4))\n",
    "\n",
    "print(\"mae on test \", round(test_mae_score, 4))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
